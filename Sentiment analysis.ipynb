{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronics Category Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = BeautifulSoup(open('/Users/praga/Downloads/electronics/positive.review').read())\n",
    "positive_reviews = positive_reviews.findAll('review_text')\n",
    "\n",
    "negative_reviews = BeautifulSoup(open('/Users/praga/Downloads/electronics/negative.review').read())\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling the Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = len(positive_reviews) - len(negative_reviews)\n",
    "idxs = np.random.choice(len(negative_reviews), size=diff)\n",
    "extra = [negative_reviews[i] for i in idxs]\n",
    "negative_reviews += extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### or undersample the positive reviews\n",
    "\n",
    "# np.random.shuffle(positive_reviews)\n",
    "# positive_reviews = positive_reviews[:len(negative_reviews)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower() # downcase\n",
    "    tokens = nltk.tokenize.word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')] # remove stopwords\n",
    "    tokens= [t for t in tokens if t.isalpha()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_map = {}\n",
    "current_index = 0\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "orig_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in positive_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in negative_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<review_text>\\nI purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.  It will run my cable modem, router, PC, and LCD monitor for 5 minutes.  This is more than enough time to save work and shut down.   Equally important, I know that my electronics are receiving clean power.\\n\\nI feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\\n\\nAs always, Amazon had it to me in &lt;2 business days\\n</review_text>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'purchased unit due frequent blackout area power supply going bad run cable modem router lcd monitor minute enough time save work shut equally important know electronics receiving clean power feel investment minor compared loss valuable data failure equipment due power spike irregular power supply always amazon business day'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_0=' '.join(positive_tokenized[0])\n",
    "pos_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<review_text>\\ncons\\ntips extremely easy on carpet and if you have a lot of cds stacked at the top\\n\\npoorly designed, it is a vertical cd rack that doesnt have individual slots for cds, so if you want a cd from the bottom of a stack you have basically pull the whole stack to get to it\\n\\nputting it together was a pain, the one i bought i had to break a piece of metal just to fit it in its guide holes.\\n\\nagain..poorly designed... doesnt even fit cds that well, there are gaps, and the cd casses are loose fitting\\n\\npros\\n..........\\ni guess it can hold a lot of cds....\\n</review_text>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'con tip extremely easy carpet lot cd stacked top poorly designed vertical rack doesnt individual slot cd want bottom stack basically pull whole stack get putting together wa pain one bought break piece metal fit guide hole designed doesnt even fit cd well gap ca loose fitting pro guess hold lot cd'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_0=' '.join(negative_tokenized[0])\n",
    "neg_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input matrices (Normalized Count Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1) # last element is for the label\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] += 1\n",
    "    x = x / x.sum() # normalize it before setting label\n",
    "    x[-1] = label\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(positive_tokenized) + len(negative_tokenized)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966L, 7542L)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.zeros((N, len(word_index_map) + 1)) #data is a matrix of 1966 X 7542\n",
    "i = 0\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word_index_map is a dictionary which contains the index(location) of all the words in both positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_map['purchased'],word_index_map['unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is a matrix which has 1966 rows, which are all the reviews in each row and there are 7542 columns denoting the unique words in these reviews. The values in data matrix is the normalized count value for each of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7542"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 0.02857142857142857, 0.05714285714285714}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_reviews, data = shuffle(orig_reviews, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "Y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 100 rows will be test\n",
    "Xtrain = X[:-100,]\n",
    "Ytrain = Y[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytest = Y[-100:,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:80.28%\n",
      "Test accuracy:79.00%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print\"Train accuracy:{:1.2%}\".format(model.score(Xtrain, Ytrain))\n",
    "print\"Test accuracy:{:1.2%}\".format(model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:87.41%\n",
      "Test accuracy:82.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb=MultinomialNB()\n",
    "model_nb.fit(Xtrain, Ytrain)\n",
    "print\"Train accuracy:{:1.2%}\".format(model_nb.score(Xtrain, Ytrain))\n",
    "print\"Test accuracy:{:1.2%}\".format(model_nb.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'unit', -0.6693402198376536)\n",
      "(u'best', 1.1059264306368357)\n",
      "(u'much', 0.6370770500863964)\n",
      "(u'worked', -0.8340595805433348)\n",
      "(u'easy', 1.1159350589043164)\n",
      "(u'happy', 0.6851858331743848)\n",
      "(u'time', -0.618083341483251)\n",
      "(u'love', 0.9940843407094628)\n",
      "(u'working', -0.6559656517002291)\n",
      "(u'printer', 0.5411236225243428)\n",
      "(u'original', -0.5159647793803978)\n",
      "(u'returned', -0.5427291111267295)\n",
      "(u'cable', 0.8620004244369122)\n",
      "(u'small', 0.8062855702526749)\n",
      "(u'company', -0.5755700457455178)\n"
     ]
    }
   ],
   "source": [
    "from future.utils import iteritems\n",
    "threshold = 0.5\n",
    "i=0\n",
    "for word, index in iteritems(word_index_map):\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        if i <15:\n",
    "            print(word, weight)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'raining', -9.03033192734806)\n",
      "(u'conspiratively', -9.043577154098081)\n",
      "(u'yellow', -8.990133118936946)\n",
      "(u'four', -8.794575962309032)\n",
      "(u'gag', -9.043577154098081)\n",
      "(u'circuitry', -9.040691149208946)\n",
      "(u'hanging', -8.960560001102877)\n",
      "(u'marching', -9.028539276733541)\n",
      "(u'shure', -8.994968024757819)\n",
      "(u'looking', -8.180464248669278)\n",
      "(u'accupower', -9.030673749262172)\n",
      "(u'eligible', -9.00848583428681)\n",
      "(u'electricity', -9.015386483774035)\n",
      "(u'scold', -9.014589617224829)\n",
      "(u'unanswered', -9.043577154098081)\n"
     ]
    }
   ],
   "source": [
    "from future.utils import iteritems\n",
    "threshold = 0.5\n",
    "i=0\n",
    "for word, index in iteritems(word_index_map):\n",
    "    weight = model_nb.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        if i <15:\n",
    "            print(word, weight)\n",
    "            i+=1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words with negative weights represent negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "P = model.predict_proba(X)[:,1] # p(y = 1 | x)\n",
    "preds_nb = model_nb.predict(X)\n",
    "P_nb = model_nb.predict_proba(X)[:,1] # p(y = 1 | x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "minP_whenYis1 = 1\n",
    "maxP_whenYis0 = 0\n",
    "wrong_positive_review = None\n",
    "wrong_negative_review = None\n",
    "wrong_positive_prediction = None\n",
    "wrong_negative_prediction = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    p = P[i]\n",
    "    y = Y[i]\n",
    "    if y == 1 and p < 0.5:\n",
    "        if p < minP_whenYis1:\n",
    "            wrong_positive_review = orig_reviews[i]\n",
    "            wrong_positive_prediction = preds[i]\n",
    "            minP_whenYis1 = p\n",
    "    elif y == 0 and p > 0.5:\n",
    "        if p > maxP_whenYis0:\n",
    "            wrong_negative_review = orig_reviews[i]\n",
    "            wrong_negative_prediction = preds[i]\n",
    "            maxP_whenYis0 = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong positive review:\n",
      "\n",
      "This was a defective unit. Got new unit and it works as expected\n",
      "\n",
      "prob = 0.393088492994584, pred = 0.0, actual = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Most wrong positive review:\") \n",
    "print(wrong_positive_review)\n",
    "print('prob = %s, pred = %s, actual = 1'% (minP_whenYis1, wrong_positive_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong negative review:\n",
      "\n",
      "The Voice recorder meets all my expectations and more\n",
      "Easy to use, easy to transfer great results\n",
      "\n",
      "prob = 0.6324071475427929, pred = 1.0, actual = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Most wrong negative review:\") \n",
    "print(wrong_negative_review)\n",
    "print('prob = %s, pred = %s, actual = 0'% (maxP_whenYis0, wrong_negative_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "minP_whenYis1 = 1\n",
    "maxP_whenYis0 = 0\n",
    "wrong_positive_review = None\n",
    "wrong_negative_review = None\n",
    "wrong_positive_prediction = None\n",
    "wrong_negative_prediction = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    p = P_nb[i]\n",
    "    y = Y[i]\n",
    "    if y == 1 and p < 0.5:\n",
    "        if p < minP_whenYis1:\n",
    "            wrong_positive_review = orig_reviews[i]\n",
    "            wrong_positive_prediction = preds_nb[i]\n",
    "            minP_whenYis1 = p\n",
    "    elif y == 0 and p > 0.5:\n",
    "        if p > maxP_whenYis0:\n",
    "            wrong_negative_review = orig_reviews[i]\n",
    "            wrong_negative_prediction = preds_nb[i]\n",
    "            maxP_whenYis0 = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong positive review:\n",
      "\n",
      "The Sandisk 512 MB Secure Digitial Ultra II (SDSDH-512-901) sent to me was not the item I ordered.  I returned the item, unopened\n",
      "\n",
      "prob = 0.44208612683813353, pred = 0.0, actual = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Most wrong positive review:\") \n",
    "print(wrong_positive_review)\n",
    "print('prob = %s, pred = %s, actual = 1'% (minP_whenYis1, wrong_positive_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong negative review:\n",
      "\n",
      "I found that these DVD-Rs did not work well in my system, were unreliable and slow.  I cannot recommend them\n",
      "\n",
      "prob = 0.5404190221588154, pred = 1.0, actual = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Most wrong negative review:\") \n",
    "print(wrong_negative_review)\n",
    "print('prob = %s, pred = %s, actual = 0'% (maxP_whenYis0, wrong_negative_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:91.16%\n",
      "Test accuracy:89.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model_ada= AdaBoostClassifier(n_estimators=75)\n",
    "model_ada.fit(Xtrain, Ytrain)\n",
    "print\"Train accuracy:{:1.2%}\".format(model_ada.score(Xtrain, Ytrain))\n",
    "print\"Test accuracy:{:1.2%}\".format(model_ada.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "................................................................................................................................................................................................................................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVD Category Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = BeautifulSoup(open('/Users/praga/Downloads/sorted_data_acl/dvd/positive.review').read())\n",
    "positive_reviews = positive_reviews.findAll('review_text')\n",
    "\n",
    "negative_reviews = BeautifulSoup(open('/Users/praga/Downloads/sorted_data_acl/dvd/negative.review').read())\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<review_text>\\nI'm not sure why Sony, which now owns I Dream of Jeannie, decided to colorize the first season of this series.  Whatever the reason, you can readily tell by looking at the prices here on Amazon.com that the original black-and-white version of the first season is worth a lot more.  The reason for that is simple--I Dream of Jeannie was originally broadcast in black-and-white.  And for a television fan like myself, that's the ONLY way to watch the first season.\\n\\nThe episodes themselves are just as I remember seeing them.  Since I wasn't around in 1965, I'm pretty sure I've never seen these without the cuts that have been referenced here.  But to me, they're still pretty good.  The theme music, in my opinion, is every bit as good as the second theme, introduced when Jeannie went to color in 1966.  \\n\\nThe one thing that truly will drive the purists nuts is the fact that Sony stripped off the old Screen Gems animation from the end of every episode.  That logo was attached to so many classic shows from the 1960s and 1970s, and it is consistenly rated, along with Viacom's old blue V of Doom, as the scariest logo in the history of television.  The new Sony outro doesn't pack the same punch.\\n\\nStill, if you liked Jeannie way back when, you'll love it now, especially since you can watch it anytime you like, without commercial interruption\\n</review_text>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<review_text>\\nThis entire movie could have run in only 20 minutes and you wouldn't miss anything and might even enjoy it. Unfortunately it ran 88 minutes too long and I couldn't wait for it to end.  I saw it in the theater and the people all around me were all complaining how boring it was. At least a quarter of them walked out before the end. It's that bad. It's a shame, I love a good suspense/horror movie and the decent actors in this movies were waisted\\n</review_text>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = -len(positive_reviews) + len(negative_reviews)\n",
    "idxs = np.random.choice(len(positive_reviews), size=diff)\n",
    "extra = [positive_reviews[i] for i in idxs]\n",
    "positive_reviews += extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_map = {}\n",
    "current_index = 0\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "orig_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in positive_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in negative_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(word_index_map): 4143\n"
     ]
    }
   ],
   "source": [
    "print\"len(word_index_map):\", len(word_index_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(positive_tokenized) + len(negative_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((N, len(word_index_map) + 1))\n",
    "i = 0\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_reviews, data = shuffle(orig_reviews, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "Y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:77.78%\n",
      "Test accuracy:56.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb=MultinomialNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "print\"Train accuracy:{:1.2%}\".format(model_nb.score(X_train, y_train))\n",
    "print\"Test accuracy:{:1.2%}\".format(model_nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:88.89%\n",
      "Test accuracy:73.75%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print\"Train accuracy:{:1.2%}\".format(model.score(X_train, y_train))\n",
    "print\"Test accuracy:{:1.2%}\".format(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:95.68%\n",
      "Test accuracy:91.25%\n"
     ]
    }
   ],
   "source": [
    "model_ada= AdaBoostClassifier(n_estimators=13)\n",
    "model_ada.fit(X_train, y_train)\n",
    "print\"Train accuracy:{:1.2%}\".format(model_ada.score(X_train, y_train))\n",
    "print\"Test accuracy:{:1.2%}\".format(model_ada.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_ada.predict(X)\n",
    "P = model_ada.predict_proba(X)[:,1] # p(y = 1 | x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "minP_whenYis1 = 1\n",
    "maxP_whenYis0 = 0\n",
    "wrong_positive_review = None\n",
    "wrong_negative_review = None\n",
    "wrong_positive_prediction = None\n",
    "wrong_negative_prediction = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    p = P[i]\n",
    "    y = Y[i]\n",
    "    if y == 1 and p < 0.5:\n",
    "        if p < minP_whenYis1:\n",
    "            wrong_positive_review = orig_reviews[i]\n",
    "            wrong_positive_prediction = preds[i]\n",
    "            minP_whenYis1 = p\n",
    "    elif y == 0 and p > 0.5:\n",
    "        if p > maxP_whenYis0:\n",
    "            wrong_negative_review = orig_reviews[i]\n",
    "            wrong_negative_prediction = preds[i]\n",
    "            maxP_whenYis0 = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong positive review:\n",
      "\n",
      "he kept it real thats all i can say. aw yeah those people talkin bout its too much cussin. what u expect im from the hood and every other word i say is a cuss word. i just cant help it. everybody in the hood cusses. but anyways..\n",
      "\n",
      "prob = 0.4675154477459153, pred = 0.0, actual = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Most wrong positive review:\") \n",
    "print(wrong_positive_review)\n",
    "print('prob = %s, pred = %s, actual = 1'% (minP_whenYis1, wrong_positive_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong negative review:\n",
      "\n",
      "If you are looking for a good movie to buy for your child, pass on this one. This movie has so many drug references, i can't even begin to explain.(trust me, I just so happen to have taken acid before) This is a movie that NEVER should have been directed toward children. \n",
      "  \n",
      "   If you want your child to be drug free when he/she grows up, do not buy this\n",
      "\n",
      "prob = 0.9404172966821557, pred = 1.0, actual = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Most wrong negative review:\") \n",
    "print(wrong_negative_review)\n",
    "print('prob = %s, pred = %s, actual = 0'% (maxP_whenYis0, wrong_negative_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
